
<!-- README.md is generated from README.Rmd. Please edit that file -->
<!-- badges: start -->

![forthebadge](https://img.shields.io/badge/GEMM-Building-orange)
![forthebadge](https://forthebadge.com/images/badges/built-with-science.svg)
<!-- badges: end -->

# Recupera√ß√£o de Genomas apartir de metagenomas- Binning! <img src="imgs/1.png" align="right" width = "120px"/>

**Developer: MsC. Kelly Hidalgo**

Pipeline para reconstru√ß√£o de genomas a partir de metagenomas, usando
v√°rias ferramentas de *binning* e *DAS tools* para integrar os
resultados dos algoritmos de binning para calcular um conjunto otimizado
e n√£o redundante de MAGs (*Metagenome Assembled Genomes*) de uma √∫nica
montagem.

------------------------------------------------------------------------

## Introdu√ß√£o

### Sequenciamento massivo de metagenomas

O sequenciamento massivo ou em larga escala de metagenomas, compreende a
extra√ß√£o do DNA total de uma amostra de qualquer ambiente ou tipo de
amostra (i.e.¬†solo, agua, feces, esponjas marinas, tecidos vegetais,
etc) e o sequenciamento por uma t√©cnica chamada *shotgun*. Onde o DNA
total √© fragmentado em muitos pedacinhos, os quais s√£o sequenciados
aleatoriamente, obtendo assim as chamadas *reads*, que s√£o sequ√™ncias
pequenas.

<img src="imgs/seq1.png" align="center" width = "100%"/>

O *binning* √© uma t√©cnica bioinform√°tica para reconstruir genomas a
partir de metagenomas. O processamento inclui as seguintes fases: **1)
Sequenciamento de metagenomas**, do qual vai se obter reads; **2)
Controle de qualidade das reads**, usando ferramentas como *Trimmomatic*
s√£o filtradas as reads de baixa qualidade; **3) Montagem das reads**,
dos quais v√£o se obter contigs ou scafolds; **4) Mapeamento das reads**,
isto com o objetivo de saber a abund√¢ncia e o origem de cada read
(informa√ß√£o necess√°ria para a seguinte etapa); **5)** ***Binning***,
usando diferentes ferramentas/algoritmos (i.e.¬†*Metabat2, MaxBin,
CONCOCT, BinSanity*) que clusterizam os contigs/scalfolds baseado em
diferentes caracter√≠sticas similares tais como: n√≠veis de cobertura de
cada contig/scalfold, genes marcadores de c√≥pia √∫nica, perfil de
frequ√™ncias de tetranucleot√≠deos, formando os genomas reconstruidos
tamb√©m conhecidos como *MAGs* ou *Bins*; **6) Controle de qualidade**,
compreende o uso de ferramentas bioinform√°ticas (i.e.¬†*CheckM, DAStool*)
para √° analise da qualidade de cada um dos bins gerados, em √≠tems como
completude e contamina√ß√£o; **7) Anota√ß√£o taxon√¥mica** e **8) Anota√ß√£o
funcional**

A continua√ß√£o uma vis√£o geral do processo de **Binning**

<img src="imgs/binning.png" align="center" width = "100%"/>

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>

<div class="blue">

> **O que vai encontrar aqui:**
>
> -   Controle de qualidade de sequenciamento shotgun
>
> -   Montagem de metagenomas
>
> -   Mapeamento de reads
>
> -   Reconstru√ß√£o de genomas
>
> -   Anota√ß√£o taxon√¥mica e funcional de genomas

</div>

------------------------------------------------------------------------

# Ferramentas bioinform√°ticas

\*\*Antes de come√ßar: Use o tutorial de
[Unix](https://github.com/khidalgo85/Unix) para aprender comandos
b√°sicos em bash que ser√£o muito √∫teis para este tutorial.

## Intala√ß√£o Anaconda

√â recomend√°vel instalar Anaconda, pois √© a forma mais f√°cil para
instalar as ferramentas bioinform√°ticas necess√°rias pro desenvolvimento
deste pipeline. Anaconda √© uma distribui√ß√£o livre e aberta das
linguagens *Python* e *R*, utilizada na ci√™ncia de dados e
bioinform√°tica. As diferente vers√µes dos programas se administram
mediante um sinstema de gest√£o chamado *conda*, o qual faz bastante
simples instalar, rodar e atualizar programas.
[Aqui](https://conda.io/projects/conda/en/latest/user-guide/install/index.html)
se encontram as instru√ß√µes para a instala√ß√£o de Anaconda.

Depois de instalado, *Anaconda* e o gestor *Conda*, podram ser criados
*ambientes virtuais* par a instala√ß√£o das diferentes ferramentas
bioinform√°tica que ser√£o usadas.

> üá™üá∏ Es recomendable instalar Anaconda, pues es la forma m√°s f√°cil para
> instalar las herramientas bioinform√°ticas necesarias para el
> desarrollo de este pipeline. Anaconda es una distribuci√≥n libre y
> abierta de los lenguajes *Python* y *R*, utilizada en ciencia de datos
> y bioinform√°tica. Las diferentes versiones de los programas se
> administran mediante un sistema de gesti√≥n llamado *conda*, el cual
> hace bastante sencillo instalar, correr y actualizar programas.
> [Aqui](https://conda.io/projects/conda/en/latest/user-guide/install/index.html)
> se encuentran las instrucciones para la instalaci√≥n de Anaconda.
>
> Despu√©s de instalado *Anaconda* y su gestor *Conda*, podran ser
> creados *ambientes virtuales* para la instalaci√≥n de las diferentes
> herramientas bioinform√°ticas que ser√°n usadas.

------------------------------------------------------------------------

# I. Binning

## 0. Organizando os dados

## 0.1. Sequ√™ncias

Em este tutorial ser√° usado um dataset exemplo com quatro amostras. A
continua√ß√£o descarregue o dataset:

    # Crie um diret√≥rio para este tutorail
    mkdir binning 
    cd binning/

Agora dentro de binning crie outro diret√≥rio chamado `00.RawData`, onde
vai descarregar o dataset de exemplo para este tutorial

    mkdir 00.RawData

Para descarregar o dataset‚Ä¶

    curl -L https://figshare.com/ndownloader/articles/19015058/versions/1 -o 00.RawData/dataset.zip
    unzip 00.RawData/dataset.zip
    rm 00.RawData/dataset.zip

Com `ls`voc√™ pode ver o conte√∫do descarregado.

    ls 00.RawData

Por √∫ltimo ‚Äúlistou‚Äù (`ls`) o conte√∫do da pasta `00.RawData`, vai
observar que t√™m 4 amostras paired-end (R1 e R2)

    Sample1_1.fq.gz Sample1_2.fq.gz Sample2_1.fq.gz Sample2_2.fq.gz Sample3_1.fq.gz Sample3_2.fq.gz Sample4_1.fq.gz Sample4_2.fq.gz Sample5_1.fq.gz Sample5_2.fq.gz Sample6_1.fq.gz Sample6_2.fq.gz

√â fortemente recomendado rodar os comandos desde o diret√≥rio base, que
neste caso √©: `binning/`

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>

<div class="blue">

> **Nota importante: A maioria dos comandos que encontrar√° a
> continua√ß√£o, ter√£o um par√¢metro para definir o n√∫mero de
> n√∫cleos/threads/cpus (`-t/--threads/`) que ser√£o usados para o
> processamento de cada comando. Coloque o n√∫mero de n√∫cleos baseado na
> sua m√°quina o servidor que esteja usando para rodar as an√°lises.
> Procure n√£o usar todos os n√∫cleos dispon√≠veis.**

</div>

## 1. Controle de qualidade

## 1.1. Avalia√ß√£o da qualidade

üáßüá∑ Para a avalia√ß√£o da qualidade ser√° usado o programa
[FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) que
√© uma ferramenta que permite observar graficamente a qualidade das
sequencias de Illumina.

> üá™üá∏ Para la evaluaci√≥n de la calidad ser√° usado el programa
> [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/)
> que es una herramienta que permite observar graficamente la calidad de
> las secuencias de Illumina.

### 1.1.1. Instala√ß√£o

Las instru√ß√µes para a instala√ß√£o usando conda se encontram
[aqui](https://anaconda.org/bioconda/fastqc). No entanto neste tutorial
tamb√©m ser√£o apresentados.

Como j√° foi explicado anteriormente, com conda √© poss√≠vel criar
ambientes virtuais para instalar as ferramentas bioinform√°ticas. O
primeiro ambiente que ser√° criado se chamar√° **QualityControl**, onde se
instalaram os programas relacionados com esse processo.

> üá™üá∏ [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/)
> es una herramienta para evaluar graficamente la calidad de las
> secuencias de Illumina.
>
> Las instrucciones para instalaci√≥n usando conda se encuentran
> [aqui](https://anaconda.org/bioconda/fastqc). Sin embargo aqui en este
> tutorial tambi√©n ser√°n presentadas
>
> Como ya fue explicado anteriorimente, con conda es posible crear
> ambientes virutuales para instalar las herramientas bioinform√°ticas.
> El primer ambiente que ser√° creado se llamar√° **QualityControl**,
> donde se instalaran los programas relacionados con este proceso.

    conda create -n QualityControl

üáßüá∑ Durante o processo, o sistema perguntar√° se deseja proceder com a
crea√ß√£o do ambiente, com as op√ß√µes y/n (sim ou n√£o). Escreva `y` e
depois disso o ambiente virutal estar√° criado.

Para instalar as ferramentas dentro do ambiente anteriormente criado, √©
necess√°rio ativ√°-lo.

> üá™üá∏ Durante el proceso, el sistema preguntar√° s√≠ desea proceder con la
> creaci√≥n del ambiente, con las opciones y/n (si o no). Escriba `y` y
> despu√©s de eso el ambiente virtual estar√° creado.
>
> Para instalar las herramientas dentro del ambiente anteriormente
> creado, es necesario activarlo

    conda activate QualityControl

üáßüá∑ O ambiente estar√° ativo quando o nome se encontre ao come√ßo da linha
do comando, asssim: `(QualityControl) user@server:~/$`. Posteriormente
se procede √† instala√ß√£o do programa:

> üá™üá∏ El ambiente estar√° activo cuando el nombre de √©ste se encuentra en
> el comienzo de la linea de comando, as√≠:
> `(QualityControl) user@server:~/$`.
>
> Posteriormente se procede a la instalaci√≥n del programa:

    conda install -c bioconda fastqc

### 1.1.2. Uso

üáßüá∑ A primeira etapa do processo √© a avalia√ß√£o da qualidade das
sequ√™ncias cortas (Illumina paired end) usando *FastQC*, com o objetivo
de determianr se √© necess√°rio trimar ou filtrar as sequ√™ncias da baixa
qualidade para nos pr√≥ximos pasos.

Esta etapa √© para identificar principalmente as sequ√™ncias *outlier* com
baixa qualidade (*Q*‚ÄÑ&lt;‚ÄÑ20)

Ative o ambiente `QualityControl`:

> üá™üá∏ La primera etapa del proceso es la evaluaci√≥n de la calidad de las
> secuencias cortas (Illumina paired end) usando *FastQC*, con el
> objetivo de determinar s√≠ es necesario trimar o filtrar las secuencias
> de baja calidad en los pr√≥ximos pasos.
>
> √âsta etapa es para identificar principalmente las secuencias *outlier*
> con baja calidad (*Q*‚ÄÑ&lt;‚ÄÑ20).
>
> Active el ambiente `QualityControl`:

    conda activate QualityControl

    ## Onde vc est√°?
    pwd

üáßüá∑ Deve estar em `~/binning/`.. Se esse n√£o √© o resultado del comando
`pwd`, use o comando `cd` para chegar no diret√≥rio desejado.

> üá™üá∏ Debe estar em `~/binning/`. Si ese no es el resultado del comando
> `pwd`, use el comando `cd` para llegar en el directorio base.

Execute **FastQC**:

    ## Crie um direct√≥rio para salvar o output do FastQC
    mkdir 01.FastqcReports
    ## Run usando 10 threads
    fastqc -t 10 00.RawData/* -o 01.FastqcReports/

**Sintaxe** `fastqc [op√ß√µes] input -o output`

üáßüá∑ O comando `fastqc` tem v√°rias op√ß√µes ou par√¢metros, entre eles,
escolher o n√∫mero de n√∫cleos da m√°quina para rodar a an√°lise, para este
exemplo `-t 10`. O input √© o diret√≥rio que contem as sequ√™ncias
`00.RawData/*`, o `*` indica ao sistema que pode analisar todos os
arquivos que est√£o dentro desse diret√≥rio. O output, indicado pelo
par√¢mtero `-o`, √© o diret√≥rio onde se deseja que sejam guardados os
resultados da an√°lise. A continua√ß√£o se encontram uma explica√ß√£o
detalhada de cada output gerado.

> üá™üá∏ El comando `fastqc` tiene varias opciones o parametros, entre
> ellas, escoger el n√∫mero de n√∫cleos de la m√°quina para correr el
> an√°lisis, para este caso `-t 10`. El input es el directorio que
> contiene las secuencias `00.RawData/*`, el `*` indica al sistema que
> puede analizar todos los archivos que est√°n dentro de ese directorio.
> El output, indicado por el parametro `-o`, es el directorio donde se
> desea que sean guardados los resultados del an√°lisis. A continuaci√≥n
> se encuentra una explicaci√≥n detallada de cada output generado.

**Outputs**

üáßüá∑

-   Reportes html `.html`: Aqui √© poss√≠vel ver toda informa√ß√£o de
    qualidade graficamente.

-   Zip files `.zip`: Aqui se encontram cada um dos gr√°ficos de maneira
    separada. **IGNORE**

Descarregue os arquivos `html` e explore no seu *web browser*.

Observe as estat√≠sticas b√°sicas que se encontram na primeira tabela.
Al√≠, voc√™ pode saber quantas sequ√™ncias tem, o tamanho e o %GC. O
gr√°fico mais importante para saber a quealidade das leituras, √© o
primeiro, *Per base sequence quality*. Este gr√°fico √© um boxplot com a
distribui√ß√£o dos valores de qualidade *Phred Score* (eje y) em cada um
dos nucleot√≠deos das leituras (eje x). Se consideram sequ√™ncias de
excelente qualidade quando o *Phred Score &gt; 30*. √â norla que o pair 2
apresente uma qualidade um pouco inferior ao pair 1.

> üá™üá∏ Observe las estad√≠sticas b√°sicas que se encuentran en la primera
> tabla. All√≠, ud puede saber cuantas secuencias tiene, el tama√±o y el
> %GC. El gr√°fico m√°s importante para saber la calidad de las lecturas
> es el primero, *Per base sequence quality*. Este gr√°fico es un boxblot
> con la distribuci√≥n de los valores de calidad *Phred Score* (eje y) en
> cada uno de los nucle√≥tidos de las lecturas (eje x). Se consideran
> secuencias de excelente calidad cuando el *Phred Score &gt; 30*. Es
> normal que el pair 2 presente una calidad un poco inferior al pair 1.

### 1.2. Trimagem

> üá™üá∏ 1.2 Depuraci√≥n

üáßüá∑ [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) √© um
programa pra filtrar (remover) leituras ou *reads* curtas de baixa
qualidade.

Trimmomatic tem v√°rios par√¢metros que podem ser considerados para
filtrar leituras com baixa qualidade. No presente tutorial usaremos
alguns deles. Se quiser saber que otros par√¢metros e como funciona cada
um deles, consulte o
[manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).

> üá™üá∏ [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) es un
> programa para filtrar (remover) lecturas o *reads* cortas de baja
> calidad.
>
> Trimmomatic tiene v√°rios parametros que pueden ser considerados para
> filtrar lecturas con baja calidad. Aqui usaremos algunos. Si quiere
> saber que otros parametros y como funciona cada uno de ellos, consulte
> el
> [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).

### 1.2.1. Instala√ß√£o

üáßüá∑ Como se trata de uma ferramenta que participa dentro do processo de
control de qualidade, ser√° instalada dentro do ambiente virtual
**QualityControl**.

> Como se trata de una herramienta que participa dentro del proceso de
> control de calidad, ser√° instalada dentro del ambiente virtual
> **QualityControl**

    # Si no est√° activado el ambiente
    conda activate QualityControl

    # Instale Trimmomatic
    conda install -c bioconda trimmomatic

### 1.2.2. Uso

üáßüá∑ Segundo foi avaliado no controle de qualidade, pode ser necess√°rio
filtrar algumas leituras com qualidade baixa.

O programa Trimmomatic tem v√°rios par√¢metros que podem ser considerados
para filtrar reads com baixa qualidade. Aqui usaremos alguns. Se quer
saber que outros par√¢metros e como funciona cada um deles, consulte o
[manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).

Para os dados aqui analizados se usara a seguinte linha de comando:

> üá™üá∏ Seg√∫n fue evaluado en el control de calidad, puede ser necesario
> filtrar algunas lecturas con calidad baja.
>
> El programa Trimmomatic tiene v√°rios parametros que pueden ser
> considerados para filtrar lecturas con baja calidad. Aqui usaremos
> algunos. Si quiere saber que otros parametros y como funciona cada uno
> de ellos, consulte el
> [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).
>
> Para los datos aqui analizados se usar√° la siguiente linea de comando:

    # Activa o ambiente QualityControl
    conda activate QualityControl

    # Crie uma pasta para salvar as reads limpas
    mkdir 02.CleanData

    # Crie uma pasta para salvar as reads n√£o pareadas
    mkdir unpaired

    # Corra Trimmomatic
    trimmomatic PE -threads 10 00.RawData/Sample1_1.fastq.gz 00.RawData/Sample1_2.fastq.gz 02.CleanData/Sample1_1_paired.fastq.gz unpaired/Sample1_1_unpaired.fastq.gz 02.CleanData/Sample1_2_paired.fastq.gz unpaired/Sample1_2_unpaired.fastq.gz LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:150

üáßüá∑ Com o comando anterior voc√™ tem que rodar a linha de comando para
cada amostra. Se quiser rodar todas as amostras de maneira autom√¢tica √©
poss√≠vel usar um *loop* `for` para executar esta tarefa.

> üá™üá∏ Con el comnado anterior ud tiene que correr esa l√≠nea de comando
> para cada muestra. Si quiere correr todas las muestras de manera
> autom√°tica es posible usar un *loop* `for` para ejecutrar esta tarea.

    # loop
    for i in 00.RawData/*1.fq.gz 
    do
    BASE=$(basename $i 1.fq.gz)
    trimmomatic PE -threads 10 $i  00.RawData/${BASE}2.fq.gz 02.CleanData/${BASE}1_paired.fq.gz unpaired/${BASE}1_unpaired.fq.gz 02.CleanData/${BASE}2_paired.fq.gz unpaired/${BASE}2_unpaired.fq.gz LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
    done

**Sintaxe**
`trimmomatic PE -threads input_forward input_reverse output_forward_paired output_forward_unpaired output_reverse_paired output_reverse_unpaired [op√ß√µes]`

üáßüá∑ O comando anterior tem muitas partes. Primeiro, o nome do comando √©
`trimmomatic`, a continua√ß√£o a op√ß√£o `PE` indica para o programa que as
sequ√™ncias que ir√£o ser analisadas s√£o de tipo *paired end*. Depois se
encontram os inputs, forward (pair1) e reverse (pair2). Depois est√£o os
outputs, sendo o primeiro, as sequ√™ncias forward pareadas (limpas) e n√£o
pareadas (‚Äúdescartadas‚Äù) e depois igual para as sequ√™ncias reverse. Por
√∫ltimo se encontram os par√¢metros de filtragem. Para este caso usamos os
par√¢metros `SLIDINGWINDOW`, `LEADING` e `TRAILING`. O primeiro de eles,
gera uma janela deslizante, que em este caso vai de 4 em 4 bases,
c√°lcula a m√©dia do *Phred Score* e se estiver por baixo de 15 essas
bases ser√£o cortadas. `LEADING` corta bases do come√ßo da leitura que
estejam por debaixo do *threshold* de qualidade, igualmente faz o
`TRAILING` mas no final das leituras. `MINLEN` elimina todas as reads
com tamanho menor ao informado. Trimmomatic tem muitos mais par√¢metros
para customizar, veja no
[manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).

Durante o processo de Trimmomatic, o programa vai imprimendo na tela a
porcentagem de sequ√™ncias que sobreviveram na trimmagem. No caso do
dataset exemplo, em todas as amostras sobreviveram mais do 90% das
reads. No entanto √© necess√°rio avaliar a qualidade das sequ√™ncias limpas
usando novamente FastQC.

> üá™üá∏ El comando anterior tiene muchas partes. Primero, el nombre del
> comando es `trimmomatic`, a continuaci√≥n la opci√≥n `PE` indica para el
> programa que las secuencias que ir√°n a ser analizadas son de tipo
> *paired end*. Despu√©s se encuentran los inputs, forward (pair1) y
> reverse (pair2). Despu√©s son los outputs, siendo primero las
> secuencias forward pareadas (limpias) y no pareadas (‚Äúdescartadas‚Äù) y
> despu√©s las secuencias reverse. Por √∫ltimo se encuentran los
> parametros de filtrado. Para este caso usamos los parametros
> `SLIDINGWINDOW`, `LEADING` y `TRAILING`. El primero de ellos, genera
> una ventana deslizante, que en este caso va de 4 en 4 bases, c√°lcula
> el promedio del *Phred Score* y si est√° por debajo de 15 esas bases
> son cortadas. `LEADING` corta bases del comienzo de la lectura si
> est√°n por debajo de *threshold* de calidad, lo mismo hace `TRAILING`
> pero al final de las lecturas. `MINLEN` elimina todas las lecturas con
> tama√±o menor al informado. Trimmomatic tiene muchos m√°s par√°metros
> customizables, revise en el
> [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).
>
> Durante el proceso de Trimmomatic, e√± programa va ir imprimiendo en la
> pantalla el porcentaje de secuencias que sobrevivieron a la
> depuraci√≥n. En el caso del dataset ejemplo, en todas las muestras
> sobrevivieron mas del 90% de las reads. Sin embargo, es necesario
> evaluar la calidad de las secuencias limpias usando nuevamente FastQC.

    fastqc -t 10 02.CleanData/* -o 01.FastqcReports/

Descarregue os arquivos `.html` das sequ√™ncias pareadas
(i.e.¬†`01.FastqcReports/Sample1_1_paired_fastqc.html` y
`01.FastqcReports/Sample1_2_paired_fastqc.html`).

A qualidade das amostras melhoraram sustancialmente, por tanto est√£o
prontas para serem usadas nas pr√≥ximas etapas.

Fa√ßa uma tabela com o n√∫mero de sequ√™ncias antes e depois da trimagem
para calcular a porcentagem de *reads* que sobreveviveram ao processo.

> üá™üá∏ Haga una tabla con el n√∫mero de secuencias antes y despu√©s de la
> depuraci√≥n para calcular el porcentaje de *reads* que sobrevivieron al
> proceso.

### 1.3 Cobertura dos Metagenoma

üáßüá∑ Al√©m de limpar e trimar as sequ√™ncias com baixa qualidade, √©
necess√°rio calcular a cobertura dos metagenomas.Este programa usa a
redund√¢ncia de reads nos metagenomas para estimar a cobertura m√©dia e
prediz a quantidade de sequ√™ncias que s√£o requeridas para atingir o
*‚Äúnearly complete coverage‚Äù*, definida como ‚ÄÑ‚â•‚ÄÑ95% ou ‚ÄÑ‚â•‚ÄÑ99% de
cobertura m√©dia. A ferramenta [**NonPareil
v3.3.3**](https://nonpareil.readthedocs.io/en/latest/) ser√° usada nesta
etapa.

> üá™üá∏ Adem√°s de limpiar y *trimar* las secuencias con baja calidad, es
> necesario calcular la cobertura de los metagenomas. Este programa usa
> la redundancia de las *reads* en los metagenomas para estimar la
> cobertura promedio y predice la cantidade de secuencias que son
> requeridas para conseguir el *‚Äúnearly complete coverage‚Äù*, definida
> como ‚ÄÑ‚â•‚ÄÑ95% o ‚ÄÑ‚â•‚ÄÑ99% de la cobertura promedio. La herramienta
> [**NonPareil v3.3.3**](https://nonpareil.readthedocs.io/en/latest/)
> ser√° usada en esta etapa.

### 1.3.1. Instala√ß√£o

üáßüá∑ [NonPareil v3.3.3](https://nonpareil.readthedocs.io/en/latest/) √© uma
ferramenta que ser√° usada para o c√°lculo da cobertura dos metagenomas.
Devido a incompatibilidades com a vers√£o do Python usado para escrever
esta ferramenta, ela ser√° instalada em um ambiente diferente ao de
controle de qualidade, chamado **NonPareil**.

> üá™üá∏ [NonPareil](https://nonpareil.readthedocs.io/en/latest/) es una
> herramienta que ser√° usada para el c√°lculo de la cobertura de los
> metagenomas. Debido a incompatibilidades con la versi√≥n de Python
> usado para escribir esta herramienta, ser√° instalada en un ambiente
> diferente al de control de calidad, llamado **NonPareil**.

    # Crie o ambiente
    conda create -n NonPareil

    # Instale NonPareil
    conda install -c bioconda nonpareil

### 1.3.2. Uso

Como *input* para esta an√°lise s√≥ √© necess√°rio um pair de cada amostra,
e deve estar sem compress√£o.

    # Crie o diret√≥rio pra o output
    mkdir 03.NonPareil

    # entre no directorio
    cd 03.NonPareil

    # Copie os pair 1 da pasta 02.CleanData

    cp ../02.CleanData/*_1* ./

    # Descomprimir 
    gunzip -d *

üáßüá∑ Agora est√° tudo pronto para rodar a an√°lise, mas antes disso tome-se
o tempo para entender o comando que vai usar. Para conhecer que √© cada
um dos argumentos, explore o men√∫ de ajuda da ferramenta.

> üá™üá∏ Ahora est√° todo listo para correr el an√°lisis, pero antes de eso
> t√≥mese el tiempo para entender el comando que va a usar. Para conocer
> que es cada uno de los argumentos, explore el men√∫ de ayuda de la
> herramienta.

    # Ative o ambiente NonPareil
    conda activate NonPareil

    # Explore o men√∫ da ferramenta
    nonpareil --help

    # Comando do NonPareil para cada amostra
     nonpareil -s sample1.fq -T kmer -f fastq -b sample1 -t 10 &

No caso, se tiver v√°rias amostras pode usar o seguinte loop para
facilitar o processo.

    for i in ./*.fq
    do
    BASE=$(basename $i .fq)
    nonpareil -s $i -T kmer -f fastq -b $i -t 10
    done

**Sintaxe**

-   `-s`: caminho para o *input*
-   `-T`: algor√≠tmo a ser usado. `kmer` √© recomendado para arquivos
    `.fastq` e `alignment` √© recomendado para arquivos `.fasta`.
-   `-f`: indique aqui o formato do input (p.e. `fastq` ou `fasta`)
-   `-b`: prefixo para os *outputs*
-   `-t`: n√∫mero de threads

üáßüá∑ Ao terminar esse processo, o programa ter√° criado varios
[*outputs*](https://nonpareil.readthedocs.io/en/latest/redundancy.html#output)
por cada amostra. Descarregue os arquivos `.npo`. Os quais s√£o tabelas
delimitadas por tabula√ß√µes com seis colunas. A primeira coluna indica o
esfor√ßo de sequenciamento (em n√∫mero de reads), as demais colunas t√™m
informa√ß√£o sobre a distribui√ß√£o da redund√¢ncia a determinado esfor√ßo de
sequenciamento. Usando os arquivos `.npo` e o R, pode gr√°ficar as curvas
de satura√ß√£o. A continua√ß√£o se encontra o script. Al√©m dos arquivos
`.npo` √© necess√°rio criar um arquivo chamado `samples.txt`, o qual deve
ter tr√™s colunas (separadas por tabula√ß√µes), a primeira ter√° o nome de
cada arquivo `.npo`, a segunda o nome da amostra, e a terceira a cor em
formato JSON que vai ser usada para a curva. A continua√ß√£o se encontram
uma s√©rie de comandos no bash para gerar o arquivo, no entanto este
arquivo pode ser construido em um bloco de notas, ou incluso no excel.

> üá™üá∏ Al terminar este proceso, el programa habr√° creado varios
> [*outputs*](https://nonpareil.readthedocs.io/en/latest/redundancy.html#output)
> por cada muestra. Descargue los archivos `.npo`. Los cuales son tablas
> delimitadas por tabulaciones con seis columnas. La primera columna
> indica el esfuerzo de secuenciaci√≥n (en n√∫mero de *reads*), las dem√°s
> columnas tienen informaci√≥n sobre la distribuci√≥n de la redundancia a
> determinao esfuerzo de secuenciaci√≥n. Usando los archivos `.npo` e R,
> puede gr√°ficar las curvas de saturaci√≥n. A continuaci√≥n se encuentra
> el script.
>
> Adem√°s de los archivos `.npo` es necesario crear un archivo llamado
> `samples.txt`, el cual debe tener tres columnas (separadas por
> tabulaciones), la primera tendr√° el nombre de cada archivo `.npo`, la
> segunda el nombre de la muestra, y la tercera el color en formato JSON
> que va a ser usado para la curva. A continuaci√≥n se encontran una
> serie de comandos en bash para generar el archivo, sin embargo, este
> archivo puede ser construido en un bloc de notas, o incluso en excel.

    # Cria um arquivo com os nomes dos arquivos
    ls *.npo > files.txt

    # Cria um arquivo com os nomes das amostras

    ls *.npo | sed 's/_1_paired.fq.npo//g' > prefix.txt

Agora precisa criar uma lista de cores para diferenciar suas amostras no
gr√°fico. Use o site [IWantHue](http://medialab.github.io/iwanthue/) para
criar uma paleta com o n√∫mero de cores igual ao n√∫merop de amostras.
Copie os c√≥digos **HEX json** das cores e coloque dentro de um arquivo
(elimine as v√≠rgulas):

> üá™üá∏ Ahora necesita crear una lista de colores para diferencias sus
> muestras en el gr√°fico. Use el sitio de internet
> [IWantHue](http://medialab.github.io/iwanthue/) para crear una paleta
> con el n√∫mero de colores igual al n√∫mero de muestras. Copie los
> c√≥digos **HEX json** de los colores e coloque dentro de un archivo
> (elimine las comas):

    # Crie o arquivo
    nano colors.txt

    # Copie e cole os c√≥digos
    "#c151b6"
    "#5eb04d"
    "#7d65ce"
    "#b5b246"

Cree o arquivo final com os t√≠tulos de las columnas e una los tr√™s
arquivos gerados anteriormente:

    echo -e 'File\tName\tCol' > samples.txt

    # Unindo os arquivos dentro de samples.txt
    paste -d'\t' files.txt prefix.txt colors.txt >> samples.txt

Use `less` para explorar o arquivo, ele deve se ver assim:

    File    Name    Col
    Sample1.npo   Sample1   "#c151b6"
    Sample2.npo   Sample2   "#5eb04d"
    Sample3.npo   Sample3   "#7d65ce"
    Sample4.npo   Sample4   "#b5b246"
    Sample5.npo   Sample5   "#c75a87"
    Sample6.npo   Sample6   "#648ace"

Descarregue os arquivos `.npo` e o arquivo `samples.txt`. Usando o
seguinte script do R, grafique as curvas de satura√ß√£o. \*Nota: todos os
arquivos descarregados devem estar dentro de uma pasta s√≥, p.e.
`03.NonPareil`.

``` r
install.packages("Nonpareil") #para instalar o pacote
library(Nonpareil) # ativa o pacote
setwd("~/03.NonPareil") # determina seu diret√≥rio de trabalho (coloque o seu, onde colocou os arquivos .npo e o arquivo samples.txt)

samples <- read.table('samples.txt', sep='\t', header=TRUE, as.is=TRUE); #l√™ o arquivo samples.txt com a informa√ß√£o das amostras

attach(samples);
nps <- Nonpareil.set(File, col=Col, labels=Name, 
                     plot.opts=list(plot.observed=FALSE, 
                                    ylim = c(0, 1.05),
                                    legend.opts = FALSE)) #grafica as curvas

Nonpareil.legend(nps, x.intersp=0.5, y.intersp=0.7, pt.cex=0.5, cex=0.5) #coloca e personaliza a legenda
  
detach(samples);
summary(nps) #mostra o resumo em forma de tabela
```

Vai obter um gr√°fico com as curvas de satura√ß√£o de cada amostra, como
este:

<img src="imgs/nonpareil.png" align='center' width="80%">

üáßüá∑ As linhas tracejadas <font color='red'> vermelha </font> e
<font color='gray'> cinza </font> representam os *threshold* de 95% e
99% da cobertura m√©dia, respeitivamente. O circulo em cada curva
representa a cobertura atual das amostras, o ideal √© que esteja por cima
do primeiro *threshold*. As curvas tamb√©m apresentam a estima√ß√£o de
quanto esfor√ßo de sequenciamento √© necess√°rio (zetas no eixo x). Devido
a que se trata de um dataset exemplo que foi obtido apartir de um
subsample aleatorio de um conjunto de dados, a maioria das amostras n√£o
conseguem uma boa cobertura. As curvas reais para as amostras originais
se apresentam a continua√ß√£o:

> üá™üá∏ Las l√≠neas punteadas <font color='red'> roja </font> y
> <font color='gray'> gris </font> representam los *threshold* de 95% y
> 99% de cobertura promedio, respectivamente. El c√≠rculo en cada curva
> representa la cobertura actual de las muestras, lo ideal es que est√©n
> por encima del primer *threshold*. Las curvas tambi√©n presentan la
> estimaci√≥n de cuanto esfuerzo de secuenciaci√≥n es necesario (flechas
> en el eje x). Debido a que se trata de un dataset ejemplo que fue
> obtenido a partir de un subsample aleatorio de un conjunto de datos,
> la mayoria de las muestras no consiguen una buena cobertura. Las
> curvas reales para las muestras originais se presentan a continuaci√≥n:

<img src="imgs/realnonpareil.png" align='center' width="80%">

### 1.4. An√°lise de Dist√¢ncias MinHash

üáßüá∑ Ap√≥s obter as sequ√™ncias limpas, de boa qualidade, e determinar a
cobertura dos metagenomas, √© poss√≠vel fazer a montagem. No entanto, pode
ser inclu√≠do um passo extra antes da montagem e √© verificar a
similaridade dos datasets para determinar se pode ser usada a abordagem
de *co-assembly*, onde s√£o misturadas as *reads* de v√°rios metagenomas
para gerar os contigs. O programa [**Mash
v2.3**](https://mash.readthedocs.io/en/latest/) usa uma t√©cnica chamada
redu√ß√£o de dimensionalidad *MinHash* que avalia as dist√¢ncias um a um
entre os datasets.

> üá™üá∏ Despu√©s de obtener las secuencias limpias, de buena calidad, y
> determinar la cobertura de los metagenomas, es posible hacer el
> montaje. Sin embargo, puede ser inclu√≠do un paso extra antes del
> montaje y es verificar la similaridade de los datasets para determinar
> si puede ser usado el abordaje de *co-assembly*, donde son mezcladas
> las *reads* de varios metagenomas para generar los contigs. El
> programa [**Mash v2.3**](https://mash.readthedocs.io/en/latest/) usa
> una t√©cnica llamada reducci√≥n de dimensionalidad *MinHash* que evalua
> las distancias un a un entre los datasets.

### 1.4.1. Instala√ß√£o

üáßüá∑ [Mash v2.3](https://mash.readthedocs.io/en/latest/) √© uma ferramenta
que usa a t√©cnica de redu√ß√£o da dimensionalidade *MinHash* para calcular
as dist√¢ncias um a um entre os datasets, assim, √© poss√≠vel determinar se
os metagenomas s√£o similares ou n√£o para serem montados usando
*co-assembly*.

üáßüá∑ Por ser considerada uma ferramenta que participa no processo de
assembly, ser√° instalada dentro de um ambiente virtual chamado
**Assembly**.

> üá™üá∏ [Mash](https://mash.readthedocs.io/en/latest/) es una herramienta
> que usa la t√©cnica de reducci√≥n de dimensionalidad *MinHash* para
> calcular las distancias un a un entre los datasets, as√≠, es posible
> determinar si los metagenomas son similares o no para ser ensamblados
> usando *co-assembly*.
>
> üá™üá∏ Por ser considera una herramienta que participa en el proceso de
> ensamble, ser√° instalada dentro de un ambiente virtual llamado
> **Assebly**.

    # Crie o ambiente virtual
    conda create -n Assembly

    # Instale Mash
    conda install -c bioconda mash

### 1.4.2. Uso

    ## Crie uma pasta para o output
    mkdir 04.MinHash

üáßüá∑ O primeiro paso √© concatenar os reads 1 e 2, e armazenar eles na nova
pasta criada `04.MinHash/`.

**Nota:** Se voc√™ trimou suas sequ√™ncias, deve usar os arquivos gerados
pelo **Trimmomatic** na pasta `02.CleanData`, se pelo contr√°rio suas
sequ√™ncias estavam de boa qualidade e n√£o foi necess√°rio trimar, use os
arquivos originais, que est√£o dentro da pasta `00.RawData/`.

> üá™üá∏
>
> **Nota:** Si usted filtr√≥ sus secuencias, debe usar los archivos
> generados por **Trimmomatic** en el directorio `02.CleanData`, si por
> el contrario sus secuencias estaban de buena calidade y no fue
> necesario filtrar, use los archivos originales, que est√°n dentro de la
> carpeta `00.RawData`.

    for i in 02.CleanData/*_1_paired.fq.gz
    do
    BASE=$(basename $i _1_paired.fq.gz)
    cat $i 02.CleanData/${BASE}_2_paired.fastq.gz > 04.MinHash/${BASE}.fq
    done

üáßüá∑ Depois ser√° criado um *sketch* para combinar todas as amostras.
Usando `mash info` pode verificar o conte√∫do e, em seguida, estimar as
dist√¢ncias par a par:

> üá™üá∏
>
> Despu√©s ser√° creado un *sketch* para combinar todas las muestras.
> Usando `mash info` puede verificar el contenido y, en seguida, estimar
> las distancias par a par:

    mash sketch -o 04.MinHash/reference 04.MinHash/sample1.fq 04.MinHash/sample2.fq 04.MinHash/sample3.fq 04.MinHash/sample4.fq 04.MinHash/sample5.fq 04.MinHash/sample6.fq

    #verifiyng
    mash info 04.MinHash/reference.msh

**Sintaxe**

`mash sketch -o reference [inputs]`

`mash info reference.msh`

-   `sketch`: Comando para criar um *sketch*, combinando todas as
    amostras, recomendado quando t√™m mais de tr√™s amostras.
-   `-o`: caminho pro *output*, criar√° um *sketch* `.msh`.
-   `inputs`: liste os inputs (sequencias concatenadas dos pair1 e
    pair2)
-   `info`: pode verificar o conte√∫do do `sketch`
-   `reference.msh`: *sketch* criado

Por √∫ltimo, calcule as dist√¢ncias entre cada par de metagenomas usando
`mash dist` e salve o resultado no arquivo `distancesOutput.tsv`.

    mash dist 04.MinHash/reference.msh 04.MinHash/reference.msh -p 6 > 04.MinHash/distancesOutputFinal.tsv

**Sintaxe** `mash dist [reference] [query] [options]`

-   `dist`: comando para calcular as dist√¢ncias entre cada par de
    mategenomas, baseado na dist√¢ncia *MinHash*.
-   `reference`: aqui pode colocar o *sketch* criado, ou arquivos `.fq`,
    `fasta`.
-   `query`: √≠dem
-   `-p`: n√∫mero de threads

Descarregue o output (`04.MinHash/distancesOutputFinal.tsv`) e use o
seguinte script do R para plotar um heatmap com as dist√¢ncias.

``` r
setwd("~/04.MinHash/")

 data <- read.table("distancesOutputFinal.tsv")

 #install.packages("vegan")
 library(vegan)
 set.seed(2)
 
 dst = as.matrix(data)
 
 #install.packages("gplots")
 library(gplots)
 set.seed(2)
 x <- matrix(rnorm(100), nrow = 5)
 dist.fn <- function(x) as.dist(1-cor(t(x)))
 hclust.com <- function(x) hclust(x, method="complete")
 
 dev.off()
 h.ori <- heatmap.2(dst, trace="none", distfun=dist.fn, 
                    hclustfun=hclust.com,dendrogram = "row",main = "MinHash Clusterization",
                    cexRow=0.8, # Tamanho do texto no eixo y
                    cexCol=0.8,adjCol = c(0.5,0.2),
                    adjRow = c(0.05,0.),
                    srtCol=90,offsetRow=0, offsetCol=0, keysize = 1.5)
```

Vai obter um heatmap com clusteriza√ß√£o similar a este:

<img src="imgs/minhash.png" align='center' width="80%">

Fa√ßa *co-assembly* para *datasets* com dist√¢ncias menores de 0.1, entre
ellas. Como pode ser observado, se formaram dois grandes cluster as
amostras 1 a 3 e amostras 4 a 6. No entanto, os dois clusters s√£o
pro√≥ximos entre eles. Por tanto podem ser montados todos em um
co-assembly s√≥.

## 2. Montagem dos Metagenomas

üáßüá∑ A montagem dos metagenomas √© a etapa mais importante do processo,
porque os demais passos para adelante dependen de uma boa montagem. No
caso dos metagenomas, se trata de um proceso que n√£o √© para nada
trivial, requer um grande esfor√ßo computacional. Por este motivo, ser√£o
testados v√°rios par√¢metros, para comparar cada montagem e decidir qual √©
o melhor para √°s an√°lises *downstream*. Neste processo ser√° usado o
montador [Spades v3.15.3](https://github.com/ablab/spades).

> üá™üá∏ El montaje de los metagenomas es la etapa m√°s importante del
> proceso, porque los dem√°s pasos para adelante dependen de un buen
> ensamble. En el caso de los metagenomas, se trata de un proceso que no
> es para nada trivial, requiere un gran esfuerzo computacional. Por
> este motivo ser√°n testados varios par√°metros, para comparar cada
> ensamble y decidir cual es el mejor para los an√°lisis *downstream*. En
> este proceso ser√° usado el montado [Spades
> v3.15.3](https://github.com/ablab/spades).

### 2.1. Instala√ß√£o

üáßüá∑ [Spades v3.15.3](https://github.com/ablab/spades) √© um dos montadores
de genomas e metagenomas, mais conhecido e com melhores resultados, pode
ser usado tanto para leituras curtas como longas. Leia atentamente o
[manual](http://cab.spbu.ru/files/release3.15.2/manual.html), j√° que
este programa tem muitas op√ß√µes diferentes. Spades usa o algor√≠tmo do
*Grafo de Bruijn* para a montagem das secu√™ncias.

Siga as seguintes instru√ß√µes para a instala√ß√£o do **Spades** dentro do
ambiente virtual *Assembly*.

> üá™üá∏ [Spades v3.15.3](https://github.com/ablab/spades) es uno de los
> ensambladores de genomas y metagenomas, m√°s conocido y con mejores
> resultados, puede ser usado tanto para lecturas cortas como largas.
> Lea atentamente el
> [manual](http://cab.spbu.ru/files/release3.15.2/manual.html), ya que
> este programa tiene muchas opciones diferentes. Spades usa el
> algor√≠tmo del *Grafo de Bruijn* para el montaje de las secuencias.
>
> Siga las siguientes instrucciones para la instalaci√≥n de **Spades**
> dentro del ambiente virtual *Assembly*.

    # Active el ambiente virtual
    conda activate Assembly

    # Instale Spades
    conda install -c bioconda spades

### 2.2. Uso

üáßüá∑ Agora √© momento de fazer as montagens. Use o resultado da an√°lisis de
dist√¢ncias *MinHash* para decidir como ser√£o feitos as montagens.
Amostras muito pr√≥ximas pode fazer *co-assembly*, para amostras
distantes √© recomendado montar individualmente. Opcionalmente podem ser
usadas as sequ√™ncias no pareadas (sequ√™ncias ‚Äúdescartadas‚Äù pelo
Trimmomatic). O montador usado neste m√©todo ser√°
[Spades](https://github.com/ablab/spades).

A continua√ß√£o se encontram os comandos se sua **montagem for
individual** (n√£o √© o caso das amostras do tutorial, veja mais para
frente):

> üá™üá∏ Ahora es el momento de hacer los ensamblajes. Use el resultado del
> an√°lisis de distancias *MinHash* para decidir como ser√°n hechos los
> montajes. Muestras muy pr√≥xima puede hacer *co-assembly*, para
> muestras distantes es recomendado montar individualmente.
> Opcionalmente pueden ser las secuencias no pareadas (secuencias
> ‚Äúdescartadas‚Äù por Trimmomatic). El montador usado en este m√©todo ser√°
> [Spades](https://github.com/ablab/spades).

> A continuaci√≥n se encuentran los comandos si su **ensamble fuera
> individual** (no es el caso de las muestras de este tutorial, vea m√°s
> adelante)

1.  Criar um diret√≥rio para todas as montagens

<!-- -->

    mkdir 05.Assembly

2.  Se voc√™ quiser usar as *reads* no pareadas (sa√≠da do
    **Trimmomatic**), deve primeiro concatenarlas em um arquivo s√≥

<!-- -->

    cat unpaired/Sample1_1_unpaired.fq.gz unpaired/Sample1_2_unpaired.fq.gz > unpaired/Sample1_12_unpaired.fq.gz

3.  Montagem com MetaSpades

<!-- -->

    metaspades.py -o 05.Assembly/Sample1/ -1 02.CleanData/Sample1_1_paired.fq.gz -2 02.CleanData/Sample1_2_paired.fq.gz -s unpaired/Sample1_12_unpaired.fq.gz -t 10 -m 100 -k 21,29,39,59,79,99,119

**Sintaxe**

-   `metaspades.py`: script para montar metagenomas
-   `-o`: caminho para diret√≥rio de sa√≠da
-   `-1`: caminho para diret√≥rio do pair1
-   `-2`: caminho para diret√≥rio do pair2
-   `-s`: caminho para diret√≥rio das *reads* no pareadas
-   `-t`: n√∫mero de threads
-   `-m`: Mem√≥ria em gigas (m√°ximo)
-   `-k`: lista de *k-mers*

üáßüá∑ No caso particular das amostras deste tutorial, ser√£o montadas em um
co-assembly s√≥. Por tanto siga as seguintes instru√ß√µes:

Se sua montagem for no modo *co-assembly* deve fazer uma etapa anterior,
onde vai concatenar todos os pair1 das amostras que ser√£o montadas e
todos os pair2 das mesmas.

> üá™üá∏ En el caso particular, las muestras de este tutorial, ser√°n
> montadas en un solo co-assembly. Por lo tanto siga las siguientes
> instrucciones: Si su ensamblaje es en el modo *co-assembly* debe hacer
> una etapa anterior, donde va a concatenar todos los pair1 de las
> muestras que ser√°n montadas y todos los pair2 de las mismas.

1.  Concatene os pair 1

<!-- -->

    cat 02.CleanData/Sample1_1.fq.gz 02.CleanData/Sample2_1.fq.gz 02.CleanData/Sample3_1.fq.gz 02.CleanData/Sample4_1.fq.gz 02.CleanData/Sample5_1.fq.gz 02.CleanData/Sample6_1.fq.gz > 02.CleanData/Sample_all_1.fq.gz

2.  Concatene os pair 2

<!-- -->

    cat 02.CleanData/Sample1_2.fq.gz 02.CleanData/Sample2_2.fq.gz 02.CleanData/Sample3_2.fq.gz 02.CleanData/Sample4_2.fq.gz 02.CleanData/Sample5_2.fq.gz 02.CleanData/Sample6_2.fq.gz > 02.CleanData/Sample_all_2.fq.gz

3.  Se voc√™ quiser usar as *reads* no pareadas (sa√≠da do
    **Trimmomatic**), deve primeiro concatenarlas em um arquivo s√≥

<!-- -->

    cat unpaired/Sample1_1_unpaired.fq.gz unpaired/Sample1_2_unpaired.fq.gz unpaired/Sample2_1_unpaired.fq.gz unpaired/Sample2_2_unpaired.fq.gz unpaired/Sample3_1_unpaired.fq.gz unpaired/Sample3_2_unpaired.fq.gz unpaired/Sample4_1_unpaired.fq.gz unpaired/Sample4_2_unpaired.fq.gz unpaired/Sample5_1_unpaired.fq.gz unpaired/Sample5_2_unpaired.fq.gz unpaired/Sample6_1_unpaired.fq.gz unpaired/Sample6_2_unpaired.fq.gz > unpaired/Sample_all_unpaired.fq.gz

4.  Montagem com MetaSpades

<!-- -->

    metaspades.py -o 05.Assembly/ -1 02.CleanData/Sample_all_1.fq.gz -2 02.CleanData/Sample_all_2.fq.gz-s unpaired/Sample_all_unpaired.fq.gz -t 10 -m 100 -k 21,29,39,59,79,99,119

**Outputs**

Para conhecer os demais par√¢metros do comando que n√£o foram modificados
(usados por *default*), consulte o
[manual](http://cab.spbu.ru/files/release3.15.2/manual.html).

-   `corrected/`: cont√©m as reads corregidas por **BayesHammer** em
    `.fastq.gz`

-   `scaffolds.fasta`: cont√©m os scaffolds obtidos

-   `contigs.fasta`: cont√©m os contigis obtidos

-   `assembly_graph_with_scaffolds.gfa`: cont√©m o grafo da montagem en
    formato GFA 1.0.

-   `assembly_graph.fastg`: cont√©m o grafo da montagem em formato FASTG

## 3. Controle de Qualidade das montagens

üáßüá∑ Para avaliar a qualidade das montagens ser√° usada a ferramenta
[**Quast v5.0.2**](http://quast.sourceforge.net/docs/manual.html)
(*QUality ASsesment Tool*), especificamente o *script* `metaquast.py`,
com o qual √© poss√≠vel determinar as principais estat√≠sticas da montagem
(i.e.¬†N50, n√∫mero de contigs, tamanho total da montagem, tamanho dos
contigs, etc). **Metaquast** gera uma s√©rie de arquivos e reportes onde
√© poss√≠vel observar essas estat√≠sticas b√°sicas da montagem. √â uma
ferramente muito √∫til para comparar montagens e escolher a melhor pro
mesmo conjunto de dados.

> üá™üá∏ Para evaluar la calidad de los montajes ser√° usada la herramienta
> [**Quast v5.0.2**](http://quast.sourceforge.net/docs/manual.html)
> (*QUality ASsesment Tool*), especificamente el *script*
> `metaquast.py`, con el cual es posible determinar las principales
> estad√≠sticas del montaje (i.e.¬†N50, n√∫mero de contigs, tama√±o total
> del montaje, tama√±o de los contigs, etc). **Metaquast** genera una
> serie de archivos y reportes donde es posible observar esas
> estad√≠sticas b√°sicas del montaje. Es una herramienta muy √∫til para
> comparar monatajes y escoger el mejor del mismo conjunto de datos.

### 3.1. Instala√ß√£o

Crie um novo ambiente virtual, chamado bioinfo, onde se instalar√°
**Quast**.

    # Crie o ambiente
    conda create -n bioinfo

    # Ative o ambiente bioinfo
    conda activate bioinfo

    # Instale Quast
    conda install -c bioconda quast

### 3.2. Uso

üáßüá∑ Se voc√™ tiver v√°rias montagens e quer comparar todas √© necess√°rio
trocar os nomes dos assemblies, j√° que eles tem todos o mesmo nome,
`contigs.fasta` ou `scaffolds.fasta`. Use o comando `mv` para trocar os
nomes. Siga o seguinte exemplo:

> üá™üá∏ Si usted tiene varios ensambles e quiere compararlos es necesario
> cambiar los nombres de los montajes, ya que todos tienen el mismo
> nombre, `contigs.fasta` ou `scaffolds.fasta`. Use el comando `mv` para
> cambiar los nombres. Siga el siguiente ejemplo:

Por exemplo:

    mv 05.Assembly/sample1/scaffolds.fasta 05.Assembly/sample1/sample1.fasta

    mv 05.Assembly/sample45/scaffolds.fasta 05.Assembly/sample45/sample45.fasta

Para as amostras deste tutorial n√£o √© necess√°rio trocar os nomes porque
s√≥ √© uma montagem:

    # Crie um diret√≥rio pro output
    mkdir 06.AssemblyQuality

    # Rode Quast
    metaquast.py 05.Assembly/scaffolds.fasta -o 06.AssemblyQuality/ --threads 10

**Sintaxis**
`metaquast.py path/to/assembly/contigs.fasta -o path/to/output/`

-   Pode colocar v√°rios inputs (montagens) separados por espa√ßo.

**Interpreta√ß√£o dos resultados**

üáßüá∑ A ideia de usar **Metaquast**, a parte de avaliar as estat√≠sticas
b√°sicas das montagens, √© comparar varias montagens para escolher a
melhor. Por exemplo: entre menor seja o n√∫mero de contigs √© melhor,
porque significa que a montagem est√° menos fragmentada. E isso ser√°
refletido no tamanho dos contigs que ser√£o maiores. O valor de N50, √©
melhor entre maior seja. Al√©m, tamb√©m √© ideal um menor n√∫mero de gaps e
Ns. No entanto, estas estat√≠sticas funcionam melhor para genomas que
para metagenomas, por se tratar de um conjunto de microrganismos.

> üá™üá∏ La idea de usar **Metaquast**, aparte de evaluar las estid√≠sticas
> b√°sicas de los montajes, es comparar varios montajes para escoger el
> mejor. Por ejemplo: entre menor sea el n√∫mero de contigs es mejor,
> porque significa que el montaje est√° menos fragementado. Y eso se
> reflejar√° en el tama√±o de los contigs que ser√°n m√°s grandes. El valor
> de N50, es mejor entre mayor sea. As√≠ mismo, es ideal menor n√∫mero de
> gaps y Ns. Sin embargo, √©stas estad√≠sticas funcionan mejor para
> genomas que para metagenomas, por tratarse de un grupo de
> microorganismos.

**Outputs**

Explore o diret√≥rio do output usando o comando `ls`.

-   `06.AssemblyQuality/report.html`: Este relat√≥rio pode ser aberto em
    um *web browser* e contem as informa√ß√µes mais relevantes. Como
    n√∫mero de contigs, tamanho del maior contig, tamanho total da
    montagem, N50, etc.

> üá™üá∏ `06.AssemblyQuality/report.html`: reporte puede ser abierto en un
> *web browser* y contiene las informaciones m√°s relevantes. Como n√∫mero
> de contigs, tama√±o del mayor contig, tama√±o total del montaje, N50,
> etc.

-   `06.AssemblyQuality/report.tex`, `06.AssemblyQuality/report.txt`,
    `06.AssemblyQuality/report.tsv`, `06.AssemblyQuality/report.pdf`: √©
    o mesmo relat√≥rio por√©m em diferentes formatos.

-   `06.AssemblyQuality/transposed_report.tsv`,
    `06.AssemblyQuality/transposed_report.tex`,
    `06.AssemblyQuality/transposed_report.tex`: Tamb√©m √© o relat√≥rio
    por√©m em formato tabular.

-   `06.AssemblyQuality/icarus_viewers/contig_size_viewer.html`:
    Visualizador das contigs

-   `06.AssemblyQuality/basis_stats/`: Dentro desta pasta se encontram
    v√°rios gr√°ficos em formato `.pdf`.

## 4. Mapping

Agora √© necess√°rio fazer o mapeamento das reads originais dentro do
co-assembly para obter informa√ß√µes de cobertura (n√∫mero de vezes que um
fragmento √© sequ√™nciado) para cada contig em cada amostra. O programa
[Bowtie2](https://github.com/BenLangmead/bowtie2) √© o elegido para esta
tarefa.

> üá™üá∏ Ahora es necesario hacer el mapeamiento de las reds dentro del
> co-assembly para obtener las informaciones de cobertura (n√∫mero de
> veces que un fragmento es secuenciado) para cada contig en cada
> muestra. El programa [Bowtie2](https://github.com/BenLangmead/bowtie2)
> es el elegido para esta tarea.

### 4.1. Instala√ß√£o

#### 4.1.1. Bowtie2

Crie um novo ambiente virtual, chamado mapping, onde se instalar√°
**Bowtie2**.

    # Crie o ambiente
    conda create -n mapping

    # Ative o ambiente mapping
    conda activate mapping

    # Instale Bowtie2
    conda install -c bioconda bowtie2

#### 4.1.2. Samtools

Para a manipula√ßao dos arquivos usaremos
[Samtools](https://github.com/samtools/samtools).

    # Crie o ambiente
    conda create -n mapping

    # Ative o ambiente samtools
    conda activate samtools

    # Instale Samtools
    conda install -c bioconda samtools=1.9

### 4.2. Uso

Ap√≥s instaldo, crie uma pasta para armazenar a sa√≠da do mapeamento

    mkdir 07.Mapping

O primeiro passo do mapeamento √© criar um √≠ndice de nosso co-assembly

    # Ative o ambiente mapping
    conda activate mapping

     bowtie2-build 05.Assembly/scaffolds.fasta 07.Mapping/final_assembly_DB

Agora vamos a mapear as reads das amostras individuais no co-assembly. O
processo pode ser feito amostra por amostra, ou podemos usar um loop
para fazer todas as amostras ao mesmo tempo. **Cuidado:** Fique atento a
nome de suas amostras, e se for necess√°rio modifique o comando, para que
se ajuste as suas amostras. &gt; üá™üá∏ Ahora vamos a mapear las reads de
las muestras individuales en el co-assembly. El proceso puede ser hecho
muestra por muestra, o puede ser usado un loop para hacer todas las
muestras al mismo tiempo. **Cuidado:** Est√© atento al nombre de sus
muestras, y si es necesario modifique el comando, para que se ajuste a
sus muestras.

    for i in 02.CleanData/*1_paired.fq.gz
    do
    BASE=$(basename $i 1_paired.fq.gz)
    bowtie2 -q -1 $i -2 02.CleanData/${BASE}2_paired.fq.gz -x 07.Mapping/final_assembly_DB -p 10 -S 07.Mapping/${BASE}.sam
    done

A linha de comando para cada amostra √©:

    bowtie2 -q -1 02.CleanData/Sample1_1.fq.gz -2 02.CleanData/Sample1_2.fq.gz -x 07.Mapping/final_assembly_DB -p 10 -S 07.Mapping/Sample1.sam

Agora √© necess√°rio converter os arquivos `.sam` para `.bam`. Tamb√©m ser√°
feito o comando usando um loop

    # Ative o ambiente Samtools
    conda activate samtools

    cd 07.Mapping/
    for f in *.sam; do filename="${f%%.*}"; samtools view -@ 10 $f -b > ${filename}.bam; done

O comando individual √©:

    samtools view -b -o 06.Mapping/sample1.bam 06.Mapping/sample1.sam

Ap√≥s transformar em arquivo `.bam`, devem ser ordenados.

    for f in *.bam; do filename="${f%%.*}"; samtools sort -@ 10 $f > ${filename}.sorted.bam; done

    ls ## conferir que estejam os arquivos

E por √∫litmo os arquivos v√£o ser indexados

    # loop
    for f in *.sorted.bam; do filename="${f%%.*}"; samtools index -@ 10 $f > ${filename}.index.bam; done

    # Comando individual
    samtools index -@ 10 sample1.sorted.bam sample1.index.bam

    ## para voltar na pasta raiz binning/
    cd ..

## 6. Binning

Para a reconstru√ß√£o dos genomas, ser√£o usadas v√°rias ferramentas para
ter um n√∫mero maior de MAGs recuperados.

> üá™üá∏ Para la reconstrucci√≥n de los genomas, ser√°n usadas varias
> herramientas para ter un n√∫mero mayor de MAGs recuperados.

### 6.1. MetaBat2

#### 6.1.1 Instala√ß√£o

Para a instala√ß√£o de algumas ferramentas de binning, ser√° criado um
ambiente chamado **Binning**.

    # Cria o ambiente
    conda create -n Binning

    # Ativa o ambiente Binning
    conda activate Binning

    # Instala Metabat2
    conda install -c bioconda metabat2

#### 6.1.2. Uso

Crie uma pasta para armazenar a sa√≠da do processamento em *MetaBat2*

    mkdir 08.MetaBat2

Usando os arquivos ordenados `.sorted.bam` vai gerar um arquivo `.txt`
com a informa√ß√£o da cobertura, necess√°ria para a recupera√ß√£o dos
genomas. Como sempre lembrando que precisa ativar o ambiente onde se
encontra instalado o *MetaBat2*

> üá™üá∏ Usando los archivos ordenados `.sorted.bam` va a ser generado un
> archivo `.txt` con la informaci√≥n de cobertura necesaria para la
> recuperaci√≥n de los genomas. Como siempre, recuerde que necesita
> activar el ambiente donde se encuentra instalado el *Metabat2*

    jgi_summarize_bam_contig_depths --outputDepth 08.MetaBat2/Depth.txt 07.Mapping/*sorted.bam

O *MetaBat2* tem v√°rios par√¢metros para customizar, o tamanho minimo de
contig √© o mais comum de ser modificado. Neste pipeline voc√™ vai
encontrar tr√™s rodadas com *MetaBat2* com diferentes tamanhos minimos de
contigs.

> üá™üá∏ *Metabat2* tiene varios par√°metros para personalizar, el tama√±o
> m√≠nimo de contig es el m√°s com√∫n de ser modificado. En este pipeline
> ud va a encontrar tres corridas con *Metabat2* con diferentes tama√±os
> m√≠nimos de contigs.

**First Trial**

Crie um diret√≥rio dentro da pasta `08.MetaBat2` chamado `01.FirstTrial`

    mkdir 08.MetaBat2/01.FirstTrial

Para este primeiro trial o tamanho minimo de contig ser√° de 1500

     metabat2 -i 05.Assembly/scaffolds.fasta -a 08.MetaBat2/Depth.txt -m 1500 -t 10 -o 08.MetaBat2/01.FirstTrial/metabat2_first_

Para o segundo trial o tamanho minimo de contig ser√° de 2500, que √© o
default da ferramenta, por isso n√£o precisa colocar o flag `-m`.

    mkdir 08.MetaBat2/02.SecondTrial

    metabat2 -i 05.Assembly/scaffolds.fasta -a 08.MetaBat2/Depth.txt -t 10 -o 08.MetaBat2/02.SecondTrial/metabat2_second_

Por √∫ltimo, para terceira rodada, ser√£o modificados mais par√¢metros.
Para conhecer todos os par√•metros que podem ser customizados, digite o
comando `metabat2 --help`. Com o flag `-m` ou `--minContig`, como j√° foi
usado nas rodadas anteriores √© poss√≠vel modificar o tamanho m√≠nimo dos
contigs, para este caso ser√° usado 3000. Com o flag `--maxEdges`,
pode-se modificar o m√°ximo n√∫mero de *edges* (arestas) por n√≥. Entre
maior seja o n√∫mero, o algoritmo √© mais sensitivo. O default √© 200, vai
ser usado 500. O flag `--minS` modifica o socre m√≠nimo de cada *edge*,
entre maior seja √© mais espec√≠fico. O default √© 60, vai ser usado 80.
Ent√£o o comando √© o seguinte:

> üá™üá∏ Por √∫ltimo, para la tercera corrida, ser√°n modificados m√°s
> par√°metros. Para conocer todos los par√°metros que puedes ser
> personalizados, digite el comando `metabat2 --help`. Con el flag `-m`
> ou `--minContig`, como ya fue usado en las corridas anteriores, es
> posible modificar el tama√±o m√≠nimo de los contigs, para este caso ser√°
> usado 3000. Con el flag `--maxEdges`, puede ser modificado el n√∫mero
> m√°ximo de *edges* (arestas) por nodo. Entre mayor sea el n√∫mero, el
> algoritmo es m√°s sensitivo. El default es 200, va a ser usado 500 para
> esta corrida. El flag `--minS` modficia el score m√≠nimo de cada
> *edge*, entre mayor sea es m√°s espec√≠fico. El default es 60, va ser
> usado 80. Entonces el comando a usar es el siguiente:

    mkdir 08.MetaBat2/03.ThirdTrial

    metabat2 -i 05.Assembly/scaffolds.fasta -a 08.MetaBat2/Depth.txt -t 10 --minContig 3000 --minCV 1.0 --minCVSum 1.0 --minS 80 --maxEdges 500 -o 08.MetaBat2/03.ThirdTrial/metabat2_third_

#### 6.2. CONCOCT

A seguinte ferramenta de reconstru√ß√£o de genomas √©
[CONCOCT](https://github.com/BinPro/CONCOCT).A qual ser√° instalada
usando o Conda.

#### 6.2.1. Instala√ß√£o

Esta ferramenta presenta alguns conflitos com outras ferramentas de
binning, principalmente na vers√£o de Python que usa. Por este motivo
ser√° criado um ambiente s√≥ para esta ferramenta.

> üá™üá∏ Esta herramienta presenta algunos conflictos con otras herramientas
> de binning, principalmente en la version de Python que usa. Por este
> motivo ser√° creado un ambiente para esta herramienta

    # Crie o ambiente
    conda create -n Concoct

    # Ative o ambiente
    conda activate Concoct

    # Instale o CONCOCT
    conda install -c bioconda concoct

#### 6.2.2. Uso

Crie uma pasta para armazenar os arquivos de sa√≠da do *CONCOCT*

    mkdir 09.CONCOCT

Primeiramente v√£o ser cortados os contigs em partes menores

    cut_up_fasta.py 05.Assembly/scaffolds.fasta -c 10000 -o 0 --merge_last -b 09.CONCOCT/contigs_10K.bed > 09.CONCOCT/contigs_10K.fa

Agora ser√° gerada uma tabela com a informa√ß√£o da cobertura por amostra e
subcontig, usando os arquivos `.sorted.bam`.

    concoct_coverage_table.py 09.CONCOCT/contigs_10K.bed 07.Mapping/*.sorted.bam > 09.CONCOCT/coverage_table.tsv

Rode o CONCOCT

    concoct --composition_file 09.CONCOCT/contigs_10K.fa --coverage_file 09.CONCOCT/coverage_table.tsv --length_threshold 1500 --threads 6 -b 09.CONCOCT/

Agora mesclar o agrupamento contig no agrupamento dos contigs originais

    merge_cutup_clustering.py 08.CONCOCT/clustering_gt1500.csv > 08.CONCOCT/clustering_merged.csv

Extrair os bins como arquivos individuais FASTA

    mkdir 09.CONCOCT/bins

    extract_fasta_bins.py 05.Assembly/scaffolds.fasta 09.CONCOCT/clustering_merged.csv --output_path 09.CONCOCT/bins

### 6.3. MaxBin2

A terceira ferramenta √© chamada
[MaxBin2](https://denbi-metagenomics-workshop.readthedocs.io/en/latest/binning/maxbin.html).

#### 6.3.1. Instala√ß√£o

O **MaxBin** ser√° instalado no ambiente **Binning**.

    # Ative o ambiente Binning
    conda ativate Binning

    # Instale o MaxBin
    conda install -c bioconda maxbin2

Adicionalmente ser√° necess√°rio instalar tamb√©m a ferramenta
[BBMAP](https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/bbmap-guide/)
no mesmo ambiente.

    # Instale o BBMAP
    conda install -c bioconda bbmap

#### 6.3.2. Uso

Primeiro crie a pasta para sa√≠da do *MaxBin2*

    mkdir 10.MaxBin2

Para obter a informa√ß√£o da cobertura s√£o usados os arquivos `.sam`. Para
facilitar, primeiro entre na pasta anteriormente criada

> üá™üá∏ Para obtener la informaci√≥n de cobertua son usados los archivos
> `.sam`. Para facilitar, primero entre en la carpeta anteiormente
> creada.

    cd 10.MaxBin2/

Copie os arquivos gerados no mapeamento (`.sam`) que se encontram na
pasta `07.Mapping/` para a pasta atual (`10.MaxBin/`).

    cp ../07.Mapping/*.sam ./

Gere os arquivos de cobertura usando o script `pile.up` da ferramenta
**BBMAP**

    for f in *.sam; do pileup.sh in=$f out=${f%}.txt; done

    cd .. ## sair da pasta para ficar na pasta base 10.MaxBin2/

Depois gere um arquivo com os nomes e caminhos dos arquivos de cobertura
gerados acima

    ls 10.MaxBin2/*sam.txt > 10.MaxBin2/abundance.list

A continua√ß√£o o comando para gerar os bins com *MaxBin*

    ## Crie um diret√≥rio para colocar os bins
    mkdir 10.MaxBin2/bins

    # Rode o MaxBin
    run_MaxBin.pl -contig 05.Assembly/scaffolds.fasta -abund_list 10.MaxBin2/abundance.list -max_iteration 20 -min_contig_length 1500 -thread 10 -out 10.MaxBin2/bins/maxbin

*MaxBin2* gera os bins com extens√£o `.fasta`, mas para facilitar as
an√°lises downstream e padronizar a mesma extens√£o dos bins gerados por
todas as ferramentas, √© melhor converter eles para `.fa`.

Para isto vamos a usar um loop for, para realizar o procedimento com
todos bins de uma vez s√≥.

> üá™üá∏ *MaxBin2* genera los bins con extensi√≥n `.fasta`, pero para
> facilitar los an√°lisis downstram e estandarizar la misma extensi√≥n
> para los bins generados por todas las herramientas, es mejor convertir
> todos para `.fa`.

    cd 10.MaxBin2/bins

    for file in *.fasta
    do mv "$file" "$(basename "$file" .fasta).fa"
    done

    ls ## para conferir que agora todos os bins terminam em .fa

    cd ../../ # para voltar √† pasta base

### 6.4. BinSanity

A quarta ferramenta se chama
[BinSanity](https://github.com/edgraham/BinSanity). Esta ferramenta ser√°
instalada em um ambiente chamado **Binsanity**

#### 6.4.1. Instala√ß√£o

Primeiro crie o ambiente, e depois instale **Binsanity**

    # Crie o ambiente
    conda create -n Binsanity

    # Ative o ambiente
    conda activate Binsanity

    # Instale Binsanity
    conda install -c bioconda binsanity

#### 6.4.2 Uso

Como sempre crie uma pasta para a sa√≠da do processamento nesta
ferramenta.

    mkdir 11.BinSanity

Gere a informa√ß√£o da cobertura das amostras

    Binsanity-profile -i 05.Assembly/scaffolds.fasta -s 07.Mapping/ -T 10 -c 11.BinSanity/coverage_profile.txt -o 11.BinSanity/

No seguinte comando ser√£o gerados os bins

    Binsanity-lc -f . -l 05.Assembly/scaffolds.fasta -x 1500 --checkm_threads 1 --Prefix binsanity_ -c 11.BinSanity/coverage_profile.txt.cov.x100.lognorm

*BinSanity* criou uma pasta com onde est√£o todos os resultados da
corrida `BINSANITY-RESULTS/` e os bins se encontram em
`BINSANITY-RESULTS/binsanity_-KMEAN-BINS/`

Ao igual que com *MaxBin* tem que converter os bins para `.fa`, com a
diferen√ßa que o *BinSanity* gera os MAGs com extens√£o `.fna`.

    cd BINSANITY-RESULTS/binsanity_-KMEAN-BINS/

    for file in *.fna
    do mv "$file" "$(basename "$file" .fna).fa"
    done

    ls ## para conferir que agora todos os bins terminam em .fa

    cd ../../ # Para voltar √† pasta base

## 8. Desreplica√ß√£o com DAS TOOL

o [DasTools](https://github.com/cmks/DAS_Tool) √© uma ferramenta que
integra os resultados de diferentes ferramentas de reconstru√ß√£o de
genomas apartir de metagenomas, para determinar o conjunto otimizado de
MAGs, n√£o redundantes de uma √∫nica montagem.

> üá™üá∏ [DasTools](https://github.com/cmks/DAS_Tool) es una herramienta que
> integra los resultados de diferentes herramientas de reconstrucci√≥n de
> genomas a partir de metagenomas, para determinar el conjunto
> optimizado de MAGs, no redundantes de un √∫nico ensamble

### 8.1 Instala√ß√£o

Crie um ambiente chamado **Dastool** para instalar a ferramenta

    # Crie o ambiente
    conda create -n Dastool

    # Ative o ambiente
    conda activate Dastool

    # Adicione os channels
    conda config --add channels defaults
    conda config --add channels bioconda
    conda config --add channels conda-forge

    # Instale Das Tool
    conda install -c bioconda das_tool

### 8.2 Uso

Crie uma pasta para o output de Das Tool

    mkdir 12.DasTool

O primeiro paso √© gerar uma tabela `.tsv`, com os contigs IDs e os bin
IDs.

Nem todas as ferramentas de binning fornecem resultados em formato de
tabela `.tsv`, com o contigs IDs e os bin IDs. Para formatar isto o DAS
Tool tem um script adicional `scaffolds2bin` que converte um conjunto de
bins no formato `.fasta` em um arquivo tabular para ser usado como input
do DAS Tool. Salve as tabelas na pasta criada para DAS Tool.

    cd 08.MetaBat2/01.FirstTrial/ #entrar na pasta da primeira rodada com o MetaBat2

    Fasta_to_Scaffolds2Bin.sh -e fa > ../../12.DasTool/metabat2_firsttrial.tsv #Script pra criar a tabela

    cd ../02.SecondTrial/ 

    Fasta_to_Scaffolds2Bin.sh -e fa > ../../12.DasTool/metabat2_secondtrial.tsv

    cd ../03.ThirdTrial/

    Fasta_to_Scaffolds2Bin.sh -e fa > ../../12.DasTool/metabat2_thirdtrial.tsv

    cd ../../09.CONCOCT/bins/

    Fasta_to_Scaffolds2Bin.sh -e fa > ../../12.DasTool/concoct.tsv

    cd ../../10.MaxBin2/bins/

    Fasta_to_Scaffolds2Bin.sh -e fa > ../12.DasTool/maxbin.tsv

    cd ../BINSANITY-RESULTS/binsanity_-final_bins/

    Fasta_to_Scaffolds2Bin.sh -e fa > ../../12.DasTool/binsanity.tsv

Ap√≥s criadas as tabelas dos bins de cada ferramenta usada, √© rodado o
DAS Tool

    cd ../../12.DasTool/

    DAS_Tool -i binsanity.tsv,concoct.tsv,maxbin.tsv,metabat2_firsttrial.tsv,metabat2_secondtrial.tsv,metabat2_thirdtrial.tsv -l binsanity,concoct,maxbin,metabat2ft,metabat2st,metabat3tt -c ../05.Assembly/final.contigs.fa -t 10 -o ./ --score_threshold 0.0 --write_bins 1 --search_engine diamond

Ap√≥s terminar a corrida do *DAS Tool*, de uma olhada no arquivo
`_DASTool_summary.txt`, o qual √© uma tabela com muitas informa√ß√µes dos
bins que passaram o filtro do *DAS Tool* (p.e. ‚Äúsize‚Äù, ‚Äúcontigs‚Äù, ‚ÄúN50‚Äù,
‚ÄúbinScore‚Äù, ‚ÄúSCG\_completeness‚Äù, ‚ÄúSCG\_redundancy‚Äù)

<div class="figure" style="text-align: center">

<img src="imgs/tabela.png" alt="Tabela DASTools" width="100%" height="100%" />
<p class="caption">
Tabela DASTools
</p>

</div>

Adicionalmente, o **DAS Tool** separa os bins que passaram o *threshold*
na pasta `12.DasTool/_DASTool_bins/`.

## 8. Qualidade dos MAGs

#### 8.1. Renomeando os MAGs

Crie uma pasta para colocar todos os bins dereplicados pelo DAS Tool

    mkdir 13.MAGS
               

Use o comando `mv` para colocar os bins dereplicados na pasta `13.MAGS`.
Use o comando `ls` para confirmar que tudo deu certo.

> üá™üá∏ Use el comando `mv` para colocar los bins desreplicados na pasta
> `13.MAGS`. Use o comando `ls` para confirmar que todo funcion√≥.

    mv _DASTool_bins/* ../13.MAGS/

    ls

Agora que todos os bins est√£o numa pasta √∫nica, e para facilitar as
an√°lises seguintes, renomee os bins usando o script
[numerate.sh](https://github.com/khidalgo85/Binning/blob/master/numerate.sh).
Este script ir√° renomear, usando um nome base para todos, seguido de
n√∫meros consecutivos.

> üá™üá∏ Ahora que todos los bins est√°n en la misma carpeta, y para
> facilitar los an√°lisis siguientes, renombr√© los bins usando el script
> [numerate.sh](https://github.com/khidalgo85/Binning/blob/master/numerate.sh).
> Este script renombrar√°, usando un nombre base para todos, seguido de
> n√∫meros consecutivos.

    ./numerate.sh -d 13.MAGS -b 1 -p MAG -s .fa -o numerically -r

**SINTAXE**

    ./numerate.sh -d <pasta/com/arquivos/para/renomear> -b <n√∫mero inicial> -p sufijo -s .extens√£o -o numerically

-   `-d`: Pasta com os arquivos que quer renomear
-   `-b`: n√∫mero para iniciar a sequ√™ncia
-   `-p`: sufijo, palavra inicial
-   `-s`: prefijo/extens√£o
-   `-o`: ordem (n√∫merica)

**Nota:** Caso ao tentar rodar acuse um erro de permiss√£o, digite o
seguinte comando `chmod 777 numerate.sh` e tente novamente.

Ao final do processo, dentro da pasta `13.MAGS`, ter√° todos os bins,
nomeados como MAG1, MAG2, MAG3‚Ä¶ MAGn.

> üá™üá∏ **Nota:** Si al intentar rodar, sale un error de permisos, d√≠gite
> el siguiente comando `chmod 777 numerate.sh` e intente nuevamente.
>
> Al final del proceso, dentro de la carpeta `13.MAGS`, tendr√° todos los
> bins nombrados como MAG1, MAG2, MAG3‚Ä¶ MAGn.

#### 8.1. CheckM

#### 8.1.1. Instala√ß√£o

A qualidade dos MAGs √© avaliada usando uma ferramenta chamada
[CheckM](https://github.com/Ecogenomics/CheckM/wiki). Basicamente a
avalia√ß√£o consiste em comparar os MAGs com uma base de dados de genes de
c√≥pia √∫nica para assim saber que t√£o completo e contaminado est√° cada um
dos genomas recuperados.

Esta ferramenta pode ser instalada dentro do ambiente **QualityControl**

> üá™üá∏ La calidad de los MAGs es evaluada usando una herramienta llamada
> [CheckM](https://github.com/Ecogenomics/CheckM/wiki). Basicamente la
> evaluaci√≥n consiste en comparar los MAGs con una base de datos de
> genes de copia √∫nica, para as√≠ saber que tan completo y contaminado
> est√° cada uno de los genomas recuperados.
>
> Esta herramienta puede ser instalada dentro del ambiente
> **QualityControl**

    # Ative o ambiente QualityControl
    conda activate QualityControl

    # Instale CheckM
    conda install -c bioconda checkm-genome

#### 8.1.2. Uso

Ser√£o analisados os genomas desreplicados e renomeados (`13.MAGS`)

Agora crie uma pasta para armazenar a sa√≠da do *CheckM*:

    mkdir 14.CheckM

Para rodar o *CheckM* √© preciso criar um diret√≥rio para os arquivos
temporais que ser√£o criados enquanto a corrida.

    mkdir tmp

Lembre **SEMPRE** que **TODA** ferramenta tem um men√∫ de ajuda (`-h` ou
`--help`).

Para rodar a an√°lise de qualidade pelo *CheckM* use o seguinte comando:

    checkm lineage_wf 13.MAGS/ 14.CheckM/ -t 10 -x fa --tmpdir tmp --tab > 14.CheckM/output.txt

A continua√ß√£o um gr√°fico mostrando a disperss√£o dos MAGs segundo a
qualidade (baseado no
[MiMAG](https://www.nature.com/articles/nbt.3893)), sendo poss√≠vel
observar quantos MAGs s√£o de baixa (*Low-Quality*: *Completeness &lt; 50
& Contamination &gt; 10*), m√©dia (*Medium-Quality*: *Completeness &gt;
50 & Contamination &lt; 10*) e alta (*High-Quality*: *Completeness &gt;
90 & Contamination &lt; 5*). Para a constru√ß√£o desse gr√°fico, use este
[script](https://github.com/khidalgo85/Binning/blob/master/Checkm.R) de
R.

> üá™üá∏ A continuaci√≥n un gr√°fico mostrando la dispersi√≥n de los MAGs segun
> su calidad (baseado en
> [MiMAG](https://www.nature.com/articles/nbt.3893)), siendo posible
> observar cuantos MAGs son de baja (*Low-Quality*: *Completeness &lt;
> 50 & Contamination &gt; 10*), media (*Medium-Quality*: *Completeness
> &gt; 50 & Contamination &lt; 10*) y alta (*High-Quality*:
> *Completeness &gt; 90 & Contamination &lt; 5*). Para la construcci√≥n
> de este gr√°fico, use este
> [script](https://github.com/khidalgo85/Binning/blob/master/Checkm.R)
> de R.

<div class="figure" style="text-align: center">

<img src="imgs/checkm.png" alt="Tabela DASTools" width="100%" height="100%" />
<p class="caption">
Tabela DASTools
</p>

</div>

Observe que foi poss√≠vel recuperar um genoma de alta qualidade, 7 de
m√©dia qualidade e 8 de baixa qualidade.

------------------------------------------------------------------------

## Em constru√ß√£o‚Ä¶
